{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/__init__.py:1173: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from sklearn import svm, cross_validation\n",
    "import pylab as pl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = '/u/zexuan/caffe/caffe/'  # this file is expected to be in {caffe_root}/examples\n",
    "caffe_real_root = '/pkgs/caffe/'\n",
    "thesis_root = '/ais/gobi2/pingpong/thesis/'\n",
    "#!ls /pkgs/caffe\n",
    "import sys\n",
    "sys.path.insert(0, caffe_real_root + 'python')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/h/14/zexuan/caffe/caffe/data/ilsvrc12\n",
      "Downloading...\n",
      "--2016-04-19 23:39:13--  http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz\n",
      "Resolving dl.caffe.berkeleyvision.org (dl.caffe.berkeleyvision.org)... 169.229.222.251\n",
      "Connecting to dl.caffe.berkeleyvision.org (dl.caffe.berkeleyvision.org)|169.229.222.251|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17858008 (17M) [application/octet-stream]\n",
      "Saving to: ‘caffe_ilsvrc12.tar.gz’\n",
      "\n",
      "100%[======================================>] 17,858,008  10.1MB/s   in 1.7s   \n",
      "\n",
      "2016-04-19 23:39:15 (10.1 MB/s) - ‘caffe_ilsvrc12.tar.gz’ saved [17858008/17858008]\n",
      "\n",
      "Unzipping...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Download the caffenet model to models/bvlc_reference_caffenet directory\n",
    "!/u/zexuan/caffe/caffe/data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "if not os.path.isfile('/u/zexuan/caffe/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "    print(\"Downloading pre-trained CaffeNet model...\")\n",
    "    !~/caffe/caffe/scripts/download_model_binary.py ~/caffe/caffe/models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2000 images with 23 workers...\n",
      "Writing train/val for 2000 successfully downloaded images.\n"
     ]
    }
   ],
   "source": [
    "# Download training data into data/flickr_style directory and labels into train.txt and test.txt\n",
    "!python ~/caffe/caffe/examples/finetune_flickr_style/assemble_data.py \\\n",
    "    --workers=-1 --images=2000 --seed=1701 --label=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For your record, if you want to train the network in pure C++ tools, here is the command:\n",
    "# build/tools/caffe train \\\n",
    "#     -solver models/finetune_flickr_style/solver.prototxt \\\n",
    "#     -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \\\n",
    "#     -gpu 0\n",
    "\n",
    "niter = 2000\n",
    "# losses will also be stored in the log\n",
    "train_loss = np.zeros(niter)\n",
    "scratch_train_loss = np.zeros(niter)\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "#caffe.set_mode_cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, finetune_loss=3.325465, scratch_loss=3.537368\n",
      "\tAccuracy for fine-tuning: 0.31400000453\n",
      "\tAccuracy for training from scratch: 0.257999996841\n",
      "iter 5, finetune_loss=3.427015, scratch_loss=25.487217\n",
      "\tAccuracy for fine-tuning: 0.0529999991879\n",
      "\tAccuracy for training from scratch: 0.0769999999553\n",
      "iter 10, finetune_loss=2.374142, scratch_loss=7.607032\n",
      "\tAccuracy for fine-tuning: 0.147999999672\n",
      "\tAccuracy for training from scratch: 0.107999999449\n",
      "iter 15, finetune_loss=2.096251, scratch_loss=2.923349\n",
      "\tAccuracy for fine-tuning: 0.218000000715\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 20, finetune_loss=2.084082, scratch_loss=2.816509\n",
      "\tAccuracy for fine-tuning: 0.185000002384\n",
      "\tAccuracy for training from scratch: 0.176000002027\n",
      "iter 25, finetune_loss=1.894195, scratch_loss=2.477635\n",
      "\tAccuracy for fine-tuning: 0.401000002027\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 30, finetune_loss=1.781072, scratch_loss=2.535767\n",
      "\tAccuracy for fine-tuning: 0.303000003099\n",
      "\tAccuracy for training from scratch: 0.252999995649\n",
      "iter 35, finetune_loss=1.567094, scratch_loss=2.474348\n",
      "\tAccuracy for fine-tuning: 0.482000002265\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 40, finetune_loss=1.428843, scratch_loss=2.439757\n",
      "\tAccuracy for fine-tuning: 0.496999996901\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 45, finetune_loss=1.296362, scratch_loss=2.351182\n",
      "\tAccuracy for fine-tuning: 0.506999999285\n",
      "\tAccuracy for training from scratch: 0.287999999523\n",
      "iter 50, finetune_loss=1.077538, scratch_loss=2.377209\n",
      "\tAccuracy for fine-tuning: 0.470000001788\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 55, finetune_loss=1.294076, scratch_loss=2.476683\n",
      "\tAccuracy for fine-tuning: 0.525999999046\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 60, finetune_loss=1.329093, scratch_loss=2.559971\n",
      "\tAccuracy for fine-tuning: 0.459999999404\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 65, finetune_loss=1.102241, scratch_loss=2.428514\n",
      "\tAccuracy for fine-tuning: 0.500999996066\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 70, finetune_loss=1.195566, scratch_loss=2.515790\n",
      "\tAccuracy for fine-tuning: 0.431999996305\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 75, finetune_loss=1.341934, scratch_loss=2.371773\n",
      "\tAccuracy for fine-tuning: 0.493999990821\n",
      "\tAccuracy for training from scratch: 0.257999996841\n",
      "iter 80, finetune_loss=1.333670, scratch_loss=2.517184\n",
      "\tAccuracy for fine-tuning: 0.479999989271\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 85, finetune_loss=1.340723, scratch_loss=2.576238\n",
      "\tAccuracy for fine-tuning: 0.544999992847\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 90, finetune_loss=0.988811, scratch_loss=2.287053\n",
      "\tAccuracy for fine-tuning: 0.504999992251\n",
      "\tAccuracy for training from scratch: 0.24699999541\n",
      "iter 95, finetune_loss=1.136657, scratch_loss=2.410577\n",
      "\tAccuracy for fine-tuning: 0.557999998331\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 100, finetune_loss=0.868484, scratch_loss=2.370761\n",
      "\tAccuracy for fine-tuning: 0.51099999547\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 105, finetune_loss=0.919660, scratch_loss=2.281327\n",
      "\tAccuracy for fine-tuning: 0.561999988556\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 110, finetune_loss=1.369447, scratch_loss=2.552316\n",
      "\tAccuracy for fine-tuning: 0.478999999166\n",
      "\tAccuracy for training from scratch: 0.107999999449\n",
      "iter 115, finetune_loss=1.022499, scratch_loss=2.475577\n",
      "\tAccuracy for fine-tuning: 0.541999995708\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 120, finetune_loss=0.992258, scratch_loss=2.343912\n",
      "\tAccuracy for fine-tuning: 0.492999991775\n",
      "\tAccuracy for training from scratch: 0.176000002027\n",
      "iter 125, finetune_loss=1.010701, scratch_loss=2.303358\n",
      "\tAccuracy for fine-tuning: 0.516999995708\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 130, finetune_loss=0.863700, scratch_loss=2.345865\n",
      "\tAccuracy for fine-tuning: 0.522999995947\n",
      "\tAccuracy for training from scratch: 0.252999995649\n",
      "iter 135, finetune_loss=0.579552, scratch_loss=2.270919\n",
      "\tAccuracy for fine-tuning: 0.557999992371\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 140, finetune_loss=0.928787, scratch_loss=2.414133\n",
      "\tAccuracy for fine-tuning: 0.494999989867\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 145, finetune_loss=0.815996, scratch_loss=2.273886\n",
      "\tAccuracy for fine-tuning: 0.518999993801\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 150, finetune_loss=0.857553, scratch_loss=2.411080\n",
      "\tAccuracy for fine-tuning: 0.578999987245\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 155, finetune_loss=0.839470, scratch_loss=2.520527\n",
      "\tAccuracy for fine-tuning: 0.52499999404\n",
      "\tAccuracy for training from scratch: 0.252999995649\n",
      "iter 160, finetune_loss=0.895726, scratch_loss=2.350569\n",
      "\tAccuracy for fine-tuning: 0.586999994516\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 165, finetune_loss=0.617357, scratch_loss=2.246218\n",
      "\tAccuracy for fine-tuning: 0.468999993801\n",
      "\tAccuracy for training from scratch: 0.179999999702\n",
      "iter 170, finetune_loss=0.857413, scratch_loss=2.376193\n",
      "\tAccuracy for fine-tuning: 0.564999994636\n",
      "\tAccuracy for training from scratch: 0.115999998897\n",
      "iter 175, finetune_loss=0.888865, scratch_loss=2.329721\n",
      "\tAccuracy for fine-tuning: 0.620000004768\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 180, finetune_loss=1.005157, scratch_loss=2.403741\n",
      "\tAccuracy for fine-tuning: 0.573000013828\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 185, finetune_loss=0.860614, scratch_loss=2.376955\n",
      "\tAccuracy for fine-tuning: 0.561999994516\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 190, finetune_loss=0.877527, scratch_loss=2.263890\n",
      "\tAccuracy for fine-tuning: 0.49699999392\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 195, finetune_loss=0.900575, scratch_loss=2.517863\n",
      "\tAccuracy for fine-tuning: 0.550999999046\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 200, finetune_loss=0.858571, scratch_loss=2.410743\n",
      "\tAccuracy for fine-tuning: 0.493999999762\n",
      "\tAccuracy for training from scratch: 0.0919999994338\n",
      "iter 205, finetune_loss=0.767495, scratch_loss=2.454037\n",
      "\tAccuracy for fine-tuning: 0.546999996901\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 210, finetune_loss=0.763088, scratch_loss=2.400327\n",
      "\tAccuracy for fine-tuning: 0.548000001907\n",
      "\tAccuracy for training from scratch: 0.174000002444\n",
      "iter 215, finetune_loss=0.715353, scratch_loss=2.445707\n",
      "\tAccuracy for fine-tuning: 0.600999999046\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 220, finetune_loss=0.812656, scratch_loss=2.279440\n",
      "\tAccuracy for fine-tuning: 0.552000001073\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 225, finetune_loss=0.686541, scratch_loss=2.366451\n",
      "\tAccuracy for fine-tuning: 0.555999994278\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 230, finetune_loss=0.600346, scratch_loss=2.368829\n",
      "\tAccuracy for fine-tuning: 0.506999999285\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 235, finetune_loss=0.647173, scratch_loss=2.590997\n",
      "\tAccuracy for fine-tuning: 0.562999999523\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 240, finetune_loss=0.636378, scratch_loss=2.313833\n",
      "\tAccuracy for fine-tuning: 0.576999992132\n",
      "\tAccuracy for training from scratch: 0.179999999702\n",
      "iter 245, finetune_loss=0.950661, scratch_loss=2.436924\n",
      "\tAccuracy for fine-tuning: 0.587999993563\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 250, finetune_loss=0.676353, scratch_loss=2.342898\n",
      "\tAccuracy for fine-tuning: 0.577999997139\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 255, finetune_loss=0.799460, scratch_loss=2.417712\n",
      "\tAccuracy for fine-tuning: 0.549000000954\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 260, finetune_loss=0.598123, scratch_loss=2.454904\n",
      "\tAccuracy for fine-tuning: 0.589999997616\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 265, finetune_loss=0.627175, scratch_loss=2.404531\n",
      "\tAccuracy for fine-tuning: 0.537999996543\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 270, finetune_loss=0.673241, scratch_loss=2.313325\n",
      "\tAccuracy for fine-tuning: 0.617000007629\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 275, finetune_loss=0.573108, scratch_loss=2.293162\n",
      "\tAccuracy for fine-tuning: 0.602999997139\n",
      "\tAccuracy for training from scratch: 0.0539999993518\n",
      "iter 280, finetune_loss=0.521590, scratch_loss=2.251502\n",
      "\tAccuracy for fine-tuning: 0.616999995708\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 285, finetune_loss=0.519515, scratch_loss=2.463408\n",
      "\tAccuracy for fine-tuning: 0.651000005007\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 290, finetune_loss=0.606564, scratch_loss=2.380758\n",
      "\tAccuracy for fine-tuning: 0.603999996185\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 295, finetune_loss=0.546740, scratch_loss=2.278203\n",
      "\tAccuracy for fine-tuning: 0.590000003576\n",
      "\tAccuracy for training from scratch: 0.176000002027\n",
      "iter 300, finetune_loss=0.706747, scratch_loss=2.204523\n",
      "\tAccuracy for fine-tuning: 0.536999985576\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 305, finetune_loss=0.615079, scratch_loss=2.278291\n",
      "\tAccuracy for fine-tuning: 0.587999999523\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 310, finetune_loss=0.505384, scratch_loss=2.273106\n",
      "\tAccuracy for fine-tuning: 0.585000008345\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 315, finetune_loss=0.652885, scratch_loss=2.433817\n",
      "\tAccuracy for fine-tuning: 0.551999992132\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 320, finetune_loss=0.571163, scratch_loss=2.335945\n",
      "\tAccuracy for fine-tuning: 0.641000002623\n",
      "\tAccuracy for training from scratch: 0.26099999845\n",
      "iter 325, finetune_loss=0.711657, scratch_loss=2.329209\n",
      "\tAccuracy for fine-tuning: 0.579999995232\n",
      "\tAccuracy for training from scratch: 0.257999996841\n",
      "iter 330, finetune_loss=0.527609, scratch_loss=2.439191\n",
      "\tAccuracy for fine-tuning: 0.62199999094\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 335, finetune_loss=0.496389, scratch_loss=2.377731\n",
      "\tAccuracy for fine-tuning: 0.58599998951\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 340, finetune_loss=0.477378, scratch_loss=2.201714\n",
      "\tAccuracy for fine-tuning: 0.618000000715\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 345, finetune_loss=0.548771, scratch_loss=2.315760\n",
      "\tAccuracy for fine-tuning: 0.650999987125\n",
      "\tAccuracy for training from scratch: 0.26099999845\n",
      "iter 350, finetune_loss=0.451168, scratch_loss=2.278057\n",
      "\tAccuracy for fine-tuning: 0.642000001669\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 355, finetune_loss=0.411414, scratch_loss=2.301419\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 360, finetune_loss=0.506836, scratch_loss=2.387224\n",
      "\tAccuracy for fine-tuning: 0.652000004053\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 365, finetune_loss=0.581501, scratch_loss=2.219630\n",
      "\tAccuracy for fine-tuning: 0.604000002146\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 370, finetune_loss=0.663600, scratch_loss=2.351964\n",
      "\tAccuracy for fine-tuning: 0.605999994278\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 375, finetune_loss=0.556914, scratch_loss=2.334298\n",
      "\tAccuracy for fine-tuning: 0.592000001669\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 380, finetune_loss=0.677265, scratch_loss=2.328617\n",
      "\tAccuracy for fine-tuning: 0.658999997377\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 385, finetune_loss=0.579179, scratch_loss=2.310257\n",
      "\tAccuracy for fine-tuning: 0.608000004292\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 390, finetune_loss=0.568747, scratch_loss=2.394873\n",
      "\tAccuracy for fine-tuning: 0.582999998331\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 395, finetune_loss=0.512611, scratch_loss=2.303218\n",
      "\tAccuracy for fine-tuning: 0.594999998808\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 400, finetune_loss=0.617988, scratch_loss=2.466477\n",
      "\tAccuracy for fine-tuning: 0.503999993205\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 405, finetune_loss=0.532286, scratch_loss=2.372763\n",
      "\tAccuracy for fine-tuning: 0.603999996185\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 410, finetune_loss=0.422406, scratch_loss=2.519438\n",
      "\tAccuracy for fine-tuning: 0.606999993324\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 415, finetune_loss=0.444677, scratch_loss=2.316915\n",
      "\tAccuracy for fine-tuning: 0.52499999404\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 420, finetune_loss=0.596329, scratch_loss=2.424724\n",
      "\tAccuracy for fine-tuning: 0.559999996424\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 425, finetune_loss=0.462757, scratch_loss=2.378297\n",
      "\tAccuracy for fine-tuning: 0.589999997616\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 430, finetune_loss=0.644472, scratch_loss=2.408105\n",
      "\tAccuracy for fine-tuning: 0.551999998093\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 435, finetune_loss=0.604298, scratch_loss=2.450564\n",
      "\tAccuracy for fine-tuning: 0.613000005484\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 440, finetune_loss=0.321198, scratch_loss=2.346785\n",
      "\tAccuracy for fine-tuning: 0.65\n",
      "\tAccuracy for training from scratch: 0.24699999541\n",
      "iter 445, finetune_loss=0.676480, scratch_loss=2.290813\n",
      "\tAccuracy for fine-tuning: 0.605000001192\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 450, finetune_loss=0.383368, scratch_loss=2.372125\n",
      "\tAccuracy for fine-tuning: 0.653000003099\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 455, finetune_loss=0.443237, scratch_loss=2.276926\n",
      "\tAccuracy for fine-tuning: 0.622000002861\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 460, finetune_loss=0.580109, scratch_loss=2.408623\n",
      "\tAccuracy for fine-tuning: 0.590000009537\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 465, finetune_loss=0.637749, scratch_loss=2.450593\n",
      "\tAccuracy for fine-tuning: 0.63900000453\n",
      "\tAccuracy for training from scratch: 0.24699999541\n",
      "iter 470, finetune_loss=0.476500, scratch_loss=2.275944\n",
      "\tAccuracy for fine-tuning: 0.687999999523\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 475, finetune_loss=0.482997, scratch_loss=2.191792\n",
      "\tAccuracy for fine-tuning: 0.643999999762\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 480, finetune_loss=0.365845, scratch_loss=2.170150\n",
      "\tAccuracy for fine-tuning: 0.661000001431\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 485, finetune_loss=0.347668, scratch_loss=2.248050\n",
      "\tAccuracy for fine-tuning: 0.608000004292\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 490, finetune_loss=0.440769, scratch_loss=2.404412\n",
      "\tAccuracy for fine-tuning: 0.588999998569\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 495, finetune_loss=0.464398, scratch_loss=2.334311\n",
      "\tAccuracy for fine-tuning: 0.661000001431\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 500, finetune_loss=0.421571, scratch_loss=2.342989\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 505, finetune_loss=0.355592, scratch_loss=2.374589\n",
      "\tAccuracy for fine-tuning: 0.619999992847\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 510, finetune_loss=0.236936, scratch_loss=2.326577\n",
      "\tAccuracy for fine-tuning: 0.65000000596\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 515, finetune_loss=0.407892, scratch_loss=2.184405\n",
      "\tAccuracy for fine-tuning: 0.614999997616\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 520, finetune_loss=0.394545, scratch_loss=2.347138\n",
      "\tAccuracy for fine-tuning: 0.634000003338\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 525, finetune_loss=0.290581, scratch_loss=2.266561\n",
      "\tAccuracy for fine-tuning: 0.629000008106\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 530, finetune_loss=0.402704, scratch_loss=2.310272\n",
      "\tAccuracy for fine-tuning: 0.628000003099\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 535, finetune_loss=0.446874, scratch_loss=2.404520\n",
      "\tAccuracy for fine-tuning: 0.643999999762\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 540, finetune_loss=0.359471, scratch_loss=2.281536\n",
      "\tAccuracy for fine-tuning: 0.632999998331\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 545, finetune_loss=0.387711, scratch_loss=2.231874\n",
      "\tAccuracy for fine-tuning: 0.604000011086\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 550, finetune_loss=0.507863, scratch_loss=2.331039\n",
      "\tAccuracy for fine-tuning: 0.61400000453\n",
      "\tAccuracy for training from scratch: 0.257999996841\n",
      "iter 555, finetune_loss=0.413964, scratch_loss=2.394628\n",
      "\tAccuracy for fine-tuning: 0.622000002861\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 560, finetune_loss=0.350800, scratch_loss=2.398005\n",
      "\tAccuracy for fine-tuning: 0.619000005722\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 565, finetune_loss=0.271732, scratch_loss=2.350780\n",
      "\tAccuracy for fine-tuning: 0.625\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 570, finetune_loss=0.370307, scratch_loss=2.283676\n",
      "\tAccuracy for fine-tuning: 0.643999993801\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 575, finetune_loss=0.505818, scratch_loss=2.487941\n",
      "\tAccuracy for fine-tuning: 0.588999998569\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 580, finetune_loss=0.384126, scratch_loss=2.372253\n",
      "\tAccuracy for fine-tuning: 0.643999999762\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 585, finetune_loss=0.242058, scratch_loss=2.416938\n",
      "\tAccuracy for fine-tuning: 0.641000002623\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 590, finetune_loss=0.239368, scratch_loss=2.360219\n",
      "\tAccuracy for fine-tuning: 0.623999989033\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 595, finetune_loss=0.425177, scratch_loss=2.349980\n",
      "\tAccuracy for fine-tuning: 0.642000001669\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 600, finetune_loss=0.356530, scratch_loss=2.264674\n",
      "\tAccuracy for fine-tuning: 0.608999997377\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 605, finetune_loss=0.240915, scratch_loss=2.390357\n",
      "\tAccuracy for fine-tuning: 0.593999987841\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 610, finetune_loss=0.359561, scratch_loss=2.352594\n",
      "\tAccuracy for fine-tuning: 0.634999996424\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 615, finetune_loss=0.173600, scratch_loss=2.456343\n",
      "\tAccuracy for fine-tuning: 0.6\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 620, finetune_loss=0.427275, scratch_loss=2.283502\n",
      "\tAccuracy for fine-tuning: 0.601000005007\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 625, finetune_loss=0.459323, scratch_loss=2.458497\n",
      "\tAccuracy for fine-tuning: 0.631999993324\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 630, finetune_loss=0.453122, scratch_loss=2.312847\n",
      "\tAccuracy for fine-tuning: 0.615999996662\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 635, finetune_loss=0.559044, scratch_loss=2.415860\n",
      "\tAccuracy for fine-tuning: 0.598999994993\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 640, finetune_loss=0.397025, scratch_loss=2.450790\n",
      "\tAccuracy for fine-tuning: 0.623999994993\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 645, finetune_loss=0.343981, scratch_loss=2.298242\n",
      "\tAccuracy for fine-tuning: 0.671000015736\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 650, finetune_loss=0.318266, scratch_loss=2.305947\n",
      "\tAccuracy for fine-tuning: 0.646999996901\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 655, finetune_loss=0.296336, scratch_loss=2.216597\n",
      "\tAccuracy for fine-tuning: 0.596999996901\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 660, finetune_loss=0.219652, scratch_loss=2.237520\n",
      "\tAccuracy for fine-tuning: 0.628999996185\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 665, finetune_loss=0.428047, scratch_loss=2.408314\n",
      "\tAccuracy for fine-tuning: 0.643000006676\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 670, finetune_loss=0.359155, scratch_loss=2.368711\n",
      "\tAccuracy for fine-tuning: 0.660000002384\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 675, finetune_loss=0.382318, scratch_loss=2.292175\n",
      "\tAccuracy for fine-tuning: 0.631999999285\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 680, finetune_loss=0.341684, scratch_loss=2.234764\n",
      "\tAccuracy for fine-tuning: 0.639999997616\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 685, finetune_loss=0.250513, scratch_loss=2.327521\n",
      "\tAccuracy for fine-tuning: 0.630000001192\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 690, finetune_loss=0.255350, scratch_loss=2.243394\n",
      "\tAccuracy for fine-tuning: 0.618000006676\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 695, finetune_loss=0.369452, scratch_loss=2.284841\n",
      "\tAccuracy for fine-tuning: 0.548999994993\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 700, finetune_loss=0.314740, scratch_loss=2.255053\n",
      "\tAccuracy for fine-tuning: 0.641000002623\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 705, finetune_loss=0.407697, scratch_loss=2.277553\n",
      "\tAccuracy for fine-tuning: 0.66400000453\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 710, finetune_loss=0.507219, scratch_loss=2.461843\n",
      "\tAccuracy for fine-tuning: 0.661999994516\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 715, finetune_loss=0.345137, scratch_loss=2.212297\n",
      "\tAccuracy for fine-tuning: 0.646999996901\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 720, finetune_loss=0.339806, scratch_loss=2.213985\n",
      "\tAccuracy for fine-tuning: 0.647999995947\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 725, finetune_loss=0.504826, scratch_loss=2.268404\n",
      "\tAccuracy for fine-tuning: 0.643999993801\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 730, finetune_loss=0.307211, scratch_loss=2.406452\n",
      "\tAccuracy for fine-tuning: 0.676000005007\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 735, finetune_loss=0.318045, scratch_loss=2.276752\n",
      "\tAccuracy for fine-tuning: 0.652999997139\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 740, finetune_loss=0.270865, scratch_loss=2.337391\n",
      "\tAccuracy for fine-tuning: 0.642000007629\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 745, finetune_loss=0.274831, scratch_loss=2.237320\n",
      "\tAccuracy for fine-tuning: 0.63900000453\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 750, finetune_loss=0.408413, scratch_loss=2.462153\n",
      "\tAccuracy for fine-tuning: 0.622999995947\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 755, finetune_loss=0.506702, scratch_loss=2.337655\n",
      "\tAccuracy for fine-tuning: 0.631000000238\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 760, finetune_loss=0.258853, scratch_loss=2.398958\n",
      "\tAccuracy for fine-tuning: 0.65000000596\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 765, finetune_loss=0.263476, scratch_loss=2.322648\n",
      "\tAccuracy for fine-tuning: 0.643000000715\n",
      "\tAccuracy for training from scratch: 0.24699999541\n",
      "iter 770, finetune_loss=0.282835, scratch_loss=2.278530\n",
      "\tAccuracy for fine-tuning: 0.638999998569\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 775, finetune_loss=0.369059, scratch_loss=2.264898\n",
      "\tAccuracy for fine-tuning: 0.624000000954\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 780, finetune_loss=0.297260, scratch_loss=2.264636\n",
      "\tAccuracy for fine-tuning: 0.622999995947\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 785, finetune_loss=0.347247, scratch_loss=2.351931\n",
      "\tAccuracy for fine-tuning: 0.613999998569\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 790, finetune_loss=0.264842, scratch_loss=2.481244\n",
      "\tAccuracy for fine-tuning: 0.658999991417\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 795, finetune_loss=0.251212, scratch_loss=2.233298\n",
      "\tAccuracy for fine-tuning: 0.673000001907\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 800, finetune_loss=0.294138, scratch_loss=2.344282\n",
      "\tAccuracy for fine-tuning: 0.643000006676\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 805, finetune_loss=0.367114, scratch_loss=2.266928\n",
      "\tAccuracy for fine-tuning: 0.599000000954\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 810, finetune_loss=0.529079, scratch_loss=2.388923\n",
      "\tAccuracy for fine-tuning: 0.583999991417\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 815, finetune_loss=0.300900, scratch_loss=2.503014\n",
      "\tAccuracy for fine-tuning: 0.639999997616\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 820, finetune_loss=0.324826, scratch_loss=2.313730\n",
      "\tAccuracy for fine-tuning: 0.658000004292\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 825, finetune_loss=0.354634, scratch_loss=2.341974\n",
      "\tAccuracy for fine-tuning: 0.647000002861\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 830, finetune_loss=0.381171, scratch_loss=2.177013\n",
      "\tAccuracy for fine-tuning: 0.618999993801\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 835, finetune_loss=0.227317, scratch_loss=2.227881\n",
      "\tAccuracy for fine-tuning: 0.609000009298\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 840, finetune_loss=0.348895, scratch_loss=2.448009\n",
      "\tAccuracy for fine-tuning: 0.615000003576\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 845, finetune_loss=0.277969, scratch_loss=2.387357\n",
      "\tAccuracy for fine-tuning: 0.638999998569\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 850, finetune_loss=0.269279, scratch_loss=2.252060\n",
      "\tAccuracy for fine-tuning: 0.65\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 855, finetune_loss=0.204734, scratch_loss=2.238254\n",
      "\tAccuracy for fine-tuning: 0.667000001669\n",
      "\tAccuracy for training from scratch: 0.252999995649\n",
      "iter 860, finetune_loss=0.313465, scratch_loss=2.281162\n",
      "\tAccuracy for fine-tuning: 0.643000000715\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 865, finetune_loss=0.163088, scratch_loss=2.216835\n",
      "\tAccuracy for fine-tuning: 0.637000012398\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 870, finetune_loss=0.217561, scratch_loss=2.321885\n",
      "\tAccuracy for fine-tuning: 0.620000004768\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 875, finetune_loss=0.239329, scratch_loss=2.235980\n",
      "\tAccuracy for fine-tuning: 0.626000005007\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 880, finetune_loss=0.302094, scratch_loss=2.356373\n",
      "\tAccuracy for fine-tuning: 0.662000000477\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 885, finetune_loss=0.396039, scratch_loss=2.446349\n",
      "\tAccuracy for fine-tuning: 0.64999999404\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 890, finetune_loss=0.233061, scratch_loss=2.346012\n",
      "\tAccuracy for fine-tuning: 0.618000000715\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 895, finetune_loss=0.143581, scratch_loss=2.149278\n",
      "\tAccuracy for fine-tuning: 0.591000002623\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 900, finetune_loss=0.184540, scratch_loss=2.246018\n",
      "\tAccuracy for fine-tuning: 0.562999999523\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 905, finetune_loss=0.157550, scratch_loss=2.321816\n",
      "\tAccuracy for fine-tuning: 0.656000000238\n",
      "\tAccuracy for training from scratch: 0.252999995649\n",
      "iter 910, finetune_loss=0.190536, scratch_loss=2.310517\n",
      "\tAccuracy for fine-tuning: 0.647000002861\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 915, finetune_loss=0.106509, scratch_loss=2.318626\n",
      "\tAccuracy for fine-tuning: 0.656999993324\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 920, finetune_loss=0.291154, scratch_loss=2.201591\n",
      "\tAccuracy for fine-tuning: 0.662000006437\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 925, finetune_loss=0.189191, scratch_loss=2.467852\n",
      "\tAccuracy for fine-tuning: 0.633999991417\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 930, finetune_loss=0.343541, scratch_loss=2.301636\n",
      "\tAccuracy for fine-tuning: 0.637000006437\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 935, finetune_loss=0.267348, scratch_loss=2.336128\n",
      "\tAccuracy for fine-tuning: 0.678000003099\n",
      "\tAccuracy for training from scratch: 0.143000000715\n",
      "iter 940, finetune_loss=0.257222, scratch_loss=2.352692\n",
      "\tAccuracy for fine-tuning: 0.668000006676\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 945, finetune_loss=0.097732, scratch_loss=2.364626\n",
      "\tAccuracy for fine-tuning: 0.670000004768\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 950, finetune_loss=0.278400, scratch_loss=2.218670\n",
      "\tAccuracy for fine-tuning: 0.65000000596\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 955, finetune_loss=0.227930, scratch_loss=2.338000\n",
      "\tAccuracy for fine-tuning: 0.608000004292\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 960, finetune_loss=0.245035, scratch_loss=2.221238\n",
      "\tAccuracy for fine-tuning: 0.608999991417\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 965, finetune_loss=0.148512, scratch_loss=2.521952\n",
      "\tAccuracy for fine-tuning: 0.662999999523\n",
      "\tAccuracy for training from scratch: 0.179999999702\n",
      "iter 970, finetune_loss=0.208824, scratch_loss=2.321409\n",
      "\tAccuracy for fine-tuning: 0.653999996185\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 975, finetune_loss=0.246739, scratch_loss=2.388525\n",
      "\tAccuracy for fine-tuning: 0.631999999285\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 980, finetune_loss=0.212475, scratch_loss=2.279845\n",
      "\tAccuracy for fine-tuning: 0.577999997139\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 985, finetune_loss=0.342026, scratch_loss=2.355576\n",
      "\tAccuracy for fine-tuning: 0.563999995589\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 990, finetune_loss=0.187849, scratch_loss=2.396639\n",
      "\tAccuracy for fine-tuning: 0.586999982595\n",
      "\tAccuracy for training from scratch: 0.179999999702\n",
      "iter 995, finetune_loss=0.205787, scratch_loss=2.364325\n",
      "\tAccuracy for fine-tuning: 0.647999995947\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 1000, finetune_loss=0.367332, scratch_loss=2.253185\n",
      "\tAccuracy for fine-tuning: 0.636000001431\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 1005, finetune_loss=0.300620, scratch_loss=2.200130\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 1010, finetune_loss=0.210056, scratch_loss=2.196780\n",
      "\tAccuracy for fine-tuning: 0.634000009298\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 1015, finetune_loss=0.206722, scratch_loss=2.456220\n",
      "\tAccuracy for fine-tuning: 0.61099999547\n",
      "\tAccuracy for training from scratch: 0.137999998033\n",
      "iter 1020, finetune_loss=0.277117, scratch_loss=2.331792\n",
      "\tAccuracy for fine-tuning: 0.648000001907\n",
      "\tAccuracy for training from scratch: 0.176000002027\n",
      "iter 1025, finetune_loss=0.241084, scratch_loss=2.266977\n",
      "\tAccuracy for fine-tuning: 0.652999997139\n",
      "\tAccuracy for training from scratch: 0.116999998689\n",
      "iter 1030, finetune_loss=0.194147, scratch_loss=2.126160\n",
      "\tAccuracy for fine-tuning: 0.672000002861\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 1035, finetune_loss=0.225230, scratch_loss=2.204052\n",
      "\tAccuracy for fine-tuning: 0.625999993086\n",
      "\tAccuracy for training from scratch: 0.0529999995604\n",
      "iter 1040, finetune_loss=0.200875, scratch_loss=2.203242\n",
      "\tAccuracy for fine-tuning: 0.620999991894\n",
      "\tAccuracy for training from scratch: 0.0499999994412\n",
      "iter 1045, finetune_loss=0.131705, scratch_loss=2.373860\n",
      "\tAccuracy for fine-tuning: 0.642000001669\n",
      "\tAccuracy for training from scratch: 0.334000006318\n",
      "iter 1050, finetune_loss=0.274830, scratch_loss=2.257054\n",
      "\tAccuracy for fine-tuning: 0.637999999523\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 1055, finetune_loss=0.218360, scratch_loss=2.270540\n",
      "\tAccuracy for fine-tuning: 0.662000006437\n",
      "\tAccuracy for training from scratch: 0.252999995649\n",
      "iter 1060, finetune_loss=0.183132, scratch_loss=2.376987\n",
      "\tAccuracy for fine-tuning: 0.658999997377\n",
      "\tAccuracy for training from scratch: 0.236000001431\n",
      "iter 1065, finetune_loss=0.199016, scratch_loss=2.340532\n",
      "\tAccuracy for fine-tuning: 0.651999998093\n",
      "\tAccuracy for training from scratch: 0.24699999541\n",
      "iter 1070, finetune_loss=0.158377, scratch_loss=2.136552\n",
      "\tAccuracy for fine-tuning: 0.637999987602\n",
      "\tAccuracy for training from scratch: 0.0529999997467\n",
      "iter 1075, finetune_loss=0.124873, scratch_loss=2.297053\n",
      "\tAccuracy for fine-tuning: 0.596000009775\n",
      "\tAccuracy for training from scratch: 0.173999999464\n",
      "iter 1080, finetune_loss=0.310767, scratch_loss=2.275660\n",
      "\tAccuracy for fine-tuning: 0.653000003099\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 1085, finetune_loss=0.227259, scratch_loss=2.189920\n",
      "\tAccuracy for fine-tuning: 0.660000008345\n",
      "\tAccuracy for training from scratch: 0.165000000596\n",
      "iter 1090, finetune_loss=0.211391, scratch_loss=2.279307\n",
      "\tAccuracy for fine-tuning: 0.628999996185\n",
      "\tAccuracy for training from scratch: 0.100000000745\n",
      "iter 1095, finetune_loss=0.190302, scratch_loss=2.144613\n",
      "\tAccuracy for fine-tuning: 0.647000002861\n",
      "\tAccuracy for training from scratch: 0.26099999845\n",
      "iter 1100, finetune_loss=0.183052, scratch_loss=2.287095\n",
      "\tAccuracy for fine-tuning: 0.616999995708\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 1105, finetune_loss=0.353689, scratch_loss=2.267540\n",
      "\tAccuracy for fine-tuning: 0.615999996662\n",
      "\tAccuracy for training from scratch: 0.176000000536\n",
      "iter 1110, finetune_loss=0.319696, scratch_loss=2.299589\n",
      "\tAccuracy for fine-tuning: 0.661000001431\n",
      "\tAccuracy for training from scratch: 0.174000002444\n",
      "iter 1115, finetune_loss=0.156798, scratch_loss=2.264819\n",
      "\tAccuracy for fine-tuning: 0.632000005245\n",
      "\tAccuracy for training from scratch: 0.184000003338\n",
      "iter 1120, finetune_loss=0.202696, scratch_loss=2.371278\n",
      "\tAccuracy for fine-tuning: 0.656999999285\n",
      "\tAccuracy for training from scratch: 0.33900000453\n",
      "iter 1125, finetune_loss=0.399424, scratch_loss=2.161627\n",
      "\tAccuracy for fine-tuning: 0.639999997616\n",
      "\tAccuracy for training from scratch: 0.257999996841\n",
      "iter 1130, finetune_loss=0.233241, scratch_loss=2.422209\n",
      "\tAccuracy for fine-tuning: 0.633000004292\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 1135, finetune_loss=0.219294, scratch_loss=2.250861\n",
      "\tAccuracy for fine-tuning: 0.635000002384\n",
      "\tAccuracy for training from scratch: 0.174000002444\n",
      "iter 1140, finetune_loss=0.214820, scratch_loss=2.460605\n",
      "\tAccuracy for fine-tuning: 0.637000000477\n",
      "\tAccuracy for training from scratch: 0.179999999702\n",
      "iter 1145, finetune_loss=0.169155, scratch_loss=2.242450\n",
      "\tAccuracy for fine-tuning: 0.651000005007\n",
      "\tAccuracy for training from scratch: 0.174999997765\n",
      "iter 1150, finetune_loss=0.262725, scratch_loss=2.364254\n",
      "\tAccuracy for fine-tuning: 0.645000004768\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 1155, finetune_loss=0.249917, scratch_loss=2.198820\n",
      "\tAccuracy for fine-tuning: 0.641999989748\n",
      "\tAccuracy for training from scratch: 0.0529999991879\n",
      "iter 1160, finetune_loss=0.230719, scratch_loss=2.325749\n",
      "\tAccuracy for fine-tuning: 0.656999993324\n",
      "\tAccuracy for training from scratch: 0.0649999991059\n",
      "iter 1165, finetune_loss=0.274251, scratch_loss=2.346829\n",
      "\tAccuracy for fine-tuning: 0.639999997616\n",
      "\tAccuracy for training from scratch: 0.179999999702\n",
      "iter 1170, finetune_loss=0.151796, scratch_loss=2.364361\n",
      "\tAccuracy for fine-tuning: 0.651000005007\n",
      "\tAccuracy for training from scratch: 0.176000002027\n",
      "iter 1175, finetune_loss=0.317839, scratch_loss=2.216041\n",
      "\tAccuracy for fine-tuning: 0.648999994993\n",
      "\tAccuracy for training from scratch: 0.0469999996945\n",
      "iter 1180, finetune_loss=0.129560, scratch_loss=2.235199\n",
      "\tAccuracy for fine-tuning: 0.649000006914\n",
      "\tAccuracy for training from scratch: 0.285000000894\n",
      "iter 1185, finetune_loss=0.149796, scratch_loss=2.204013\n",
      "\tAccuracy for fine-tuning: 0.639999997616\n",
      "\tAccuracy for training from scratch: 0.169999998808\n",
      "iter 1190, finetune_loss=0.183650, scratch_loss=2.340977\n",
      "\tAccuracy for fine-tuning: 0.61099999547\n",
      "\tAccuracy for training from scratch: 0.124999999255\n",
      "iter 1195, finetune_loss=0.291707, scratch_loss=2.375426\n",
      "\tAccuracy for fine-tuning: 0.65\n",
      "\tAccuracy for training from scratch: 0.187000000477\n",
      "iter 1200, finetune_loss=0.258692, scratch_loss=2.299892\n",
      "\tAccuracy for fine-tuning: 0.653999996185\n",
      "\tAccuracy for training from scratch: 0.25\n",
      "iter 1205, finetune_loss=0.180159, scratch_loss=2.109401\n",
      "\tAccuracy for fine-tuning: 0.671000003815\n",
      "\tAccuracy for training from scratch: 0.194999998808\n",
      "iter 1210, finetune_loss=0.263778, scratch_loss=2.155616\n",
      "\tAccuracy for fine-tuning: 0.671000003815\n",
      "\tAccuracy for training from scratch: 0.169999998808\n",
      "iter 1215, finetune_loss=0.176784, scratch_loss=2.095644\n",
      "\tAccuracy for fine-tuning: 0.662999999523\n",
      "\tAccuracy for training from scratch: 0.169999998808\n",
      "iter 1220, finetune_loss=0.202880, scratch_loss=2.300765\n",
      "\tAccuracy for fine-tuning: 0.627999997139\n",
      "\tAccuracy for training from scratch: 0.183999997377\n",
      "iter 1225, finetune_loss=0.262963, scratch_loss=2.177402\n",
      "\tAccuracy for fine-tuning: 0.608999997377\n",
      "\tAccuracy for training from scratch: 0.138999998569\n",
      "iter 1230, finetune_loss=0.326224, scratch_loss=2.196326\n",
      "\tAccuracy for fine-tuning: 0.660000002384\n",
      "\tAccuracy for training from scratch: 0.13599999994\n",
      "iter 1235, finetune_loss=0.189390, scratch_loss=2.207042\n",
      "\tAccuracy for fine-tuning: 0.650999999046\n",
      "\tAccuracy for training from scratch: 0.242000000179\n",
      "iter 1240, finetune_loss=0.132504, scratch_loss=2.243223\n",
      "\tAccuracy for fine-tuning: 0.637999993563\n",
      "\tAccuracy for training from scratch: 0.271999999881\n",
      "iter 1245, finetune_loss=0.177531, scratch_loss=2.045135\n",
      "\tAccuracy for fine-tuning: 0.636000001431\n",
      "\tAccuracy for training from scratch: 0.200999997556\n",
      "iter 1250, finetune_loss=0.256761, scratch_loss=2.146716\n",
      "\tAccuracy for fine-tuning: 0.627000004053\n",
      "\tAccuracy for training from scratch: 0.292000001669\n",
      "iter 1255, finetune_loss=0.119484, scratch_loss=2.131030\n",
      "\tAccuracy for fine-tuning: 0.646999996901\n",
      "\tAccuracy for training from scratch: 0.148000001162\n",
      "iter 1260, finetune_loss=0.307435, scratch_loss=2.137014\n",
      "\tAccuracy for fine-tuning: 0.635000002384\n",
      "\tAccuracy for training from scratch: 0.127000000328\n",
      "iter 1265, finetune_loss=0.280703, scratch_loss=2.255993\n",
      "\tAccuracy for fine-tuning: 0.644000011683\n",
      "\tAccuracy for training from scratch: 0.121999999881\n",
      "iter 1270, finetune_loss=0.323067, scratch_loss=2.062820\n",
      "\tAccuracy for fine-tuning: 0.660000002384\n",
      "\tAccuracy for training from scratch: 0.278999997675\n",
      "iter 1275, finetune_loss=0.184528, scratch_loss=2.010071\n",
      "\tAccuracy for fine-tuning: 0.65\n",
      "\tAccuracy for training from scratch: 0.18599999994\n",
      "iter 1280, finetune_loss=0.271852, scratch_loss=2.201238\n",
      "\tAccuracy for fine-tuning: 0.614999997616\n",
      "\tAccuracy for training from scratch: 0.203000000119\n",
      "iter 1285, finetune_loss=0.226480, scratch_loss=2.226583\n",
      "\tAccuracy for fine-tuning: 0.602999997139\n",
      "\tAccuracy for training from scratch: 0.276000000536\n",
      "iter 1290, finetune_loss=0.125950, scratch_loss=2.280370\n",
      "\tAccuracy for fine-tuning: 0.624999988079\n",
      "\tAccuracy for training from scratch: 0.219999998808\n",
      "iter 1295, finetune_loss=0.154291, scratch_loss=2.211662\n",
      "\tAccuracy for fine-tuning: 0.636999994516\n",
      "\tAccuracy for training from scratch: 0.195999997854\n",
      "iter 1300, finetune_loss=0.248951, scratch_loss=2.111379\n",
      "\tAccuracy for fine-tuning: 0.619999998808\n",
      "\tAccuracy for training from scratch: 0.29999999851\n",
      "iter 1305, finetune_loss=0.171339, scratch_loss=2.348305\n",
      "\tAccuracy for fine-tuning: 0.632000005245\n",
      "\tAccuracy for training from scratch: 0.215000002086\n",
      "iter 1310, finetune_loss=0.332790, scratch_loss=2.273505\n",
      "\tAccuracy for fine-tuning: 0.643999999762\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 1315, finetune_loss=0.165474, scratch_loss=2.159564\n",
      "\tAccuracy for fine-tuning: 0.650999999046\n",
      "\tAccuracy for training from scratch: 0.230999998748\n",
      "iter 1320, finetune_loss=0.129460, scratch_loss=2.188397\n",
      "\tAccuracy for fine-tuning: 0.641999989748\n",
      "\tAccuracy for training from scratch: 0.228999999166\n",
      "iter 1325, finetune_loss=0.355606, scratch_loss=2.251963\n",
      "\tAccuracy for fine-tuning: 0.622999995947\n",
      "\tAccuracy for training from scratch: 0.246000002325\n",
      "iter 1330, finetune_loss=0.354272, scratch_loss=2.041047\n",
      "\tAccuracy for fine-tuning: 0.614999997616\n",
      "\tAccuracy for training from scratch: 0.161000001431\n",
      "iter 1335, finetune_loss=0.204271, scratch_loss=2.197331\n",
      "\tAccuracy for fine-tuning: 0.630000001192\n",
      "\tAccuracy for training from scratch: 0.183999998868\n",
      "iter 1340, finetune_loss=0.160915, scratch_loss=2.185091\n",
      "\tAccuracy for fine-tuning: 0.624000012875\n",
      "\tAccuracy for training from scratch: 0.197999999672\n",
      "iter 1345, finetune_loss=0.078479, scratch_loss=2.309952\n",
      "\tAccuracy for fine-tuning: 0.63599998951\n",
      "\tAccuracy for training from scratch: 0.218000000715\n",
      "iter 1350, finetune_loss=0.244853, scratch_loss=2.054050\n",
      "\tAccuracy for fine-tuning: 0.633000004292\n",
      "\tAccuracy for training from scratch: 0.240999999642\n",
      "iter 1355, finetune_loss=0.209544, scratch_loss=2.229527\n",
      "\tAccuracy for fine-tuning: 0.644000005722\n",
      "\tAccuracy for training from scratch: 0.217000000179\n",
      "iter 1360, finetune_loss=0.209391, scratch_loss=2.101264\n",
      "\tAccuracy for fine-tuning: 0.638999992609\n",
      "\tAccuracy for training from scratch: 0.263000003994\n",
      "iter 1365, finetune_loss=0.329539, scratch_loss=2.197028\n",
      "\tAccuracy for fine-tuning: 0.612999993563\n",
      "\tAccuracy for training from scratch: 0.249000000954\n",
      "iter 1370, finetune_loss=0.283720, scratch_loss=2.245831\n",
      "\tAccuracy for fine-tuning: 0.61400000453\n",
      "\tAccuracy for training from scratch: 0.247000001371\n",
      "iter 1375, finetune_loss=0.091246, scratch_loss=2.098543\n",
      "\tAccuracy for fine-tuning: 0.617000001669\n",
      "\tAccuracy for training from scratch: 0.234999999404\n",
      "iter 1380, finetune_loss=0.210226, scratch_loss=2.069744\n",
      "\tAccuracy for fine-tuning: 0.624000000954\n",
      "\tAccuracy for training from scratch: 0.254000003636\n",
      "iter 1385, finetune_loss=0.165112, scratch_loss=2.019860\n",
      "\tAccuracy for fine-tuning: 0.621000003815\n",
      "\tAccuracy for training from scratch: 0.247000004351\n",
      "iter 1390, finetune_loss=0.148331, scratch_loss=1.958804\n",
      "\tAccuracy for fine-tuning: 0.624000000954\n",
      "\tAccuracy for training from scratch: 0.228999997675\n",
      "iter 1395, finetune_loss=0.180878, scratch_loss=2.230423\n",
      "\tAccuracy for fine-tuning: 0.622999995947\n",
      "\tAccuracy for training from scratch: 0.282000005245\n",
      "iter 1400, finetune_loss=0.165325, scratch_loss=2.121310\n",
      "\tAccuracy for fine-tuning: 0.603999996185\n",
      "\tAccuracy for training from scratch: 0.23900000006\n",
      "iter 1405, finetune_loss=0.273657, scratch_loss=1.911884\n",
      "\tAccuracy for fine-tuning: 0.595999997854\n",
      "\tAccuracy for training from scratch: 0.213000002503\n",
      "iter 1410, finetune_loss=0.166497, scratch_loss=1.973601\n",
      "\tAccuracy for fine-tuning: 0.613999992609\n",
      "\tAccuracy for training from scratch: 0.222999997437\n",
      "iter 1415, finetune_loss=0.056684, scratch_loss=2.007072\n",
      "\tAccuracy for fine-tuning: 0.629000002146\n",
      "\tAccuracy for training from scratch: 0.204999999702\n",
      "iter 1420, finetune_loss=0.164321, scratch_loss=1.909684\n",
      "\tAccuracy for fine-tuning: 0.647999995947\n",
      "\tAccuracy for training from scratch: 0.231000003219\n",
      "iter 1425, finetune_loss=0.169836, scratch_loss=1.887669\n",
      "\tAccuracy for fine-tuning: 0.630000001192\n",
      "\tAccuracy for training from scratch: 0.273000000417\n",
      "iter 1430, finetune_loss=0.266516, scratch_loss=1.924924\n",
      "\tAccuracy for fine-tuning: 0.59699999094\n",
      "\tAccuracy for training from scratch: 0.27499999702\n",
      "iter 1435, finetune_loss=0.233214, scratch_loss=1.853459\n",
      "\tAccuracy for fine-tuning: 0.613000005484\n",
      "\tAccuracy for training from scratch: 0.242000004649\n",
      "iter 1440, finetune_loss=0.247838, scratch_loss=2.224732\n",
      "\tAccuracy for fine-tuning: 0.655000001192\n",
      "\tAccuracy for training from scratch: 0.26099999994\n",
      "iter 1445, finetune_loss=0.157556, scratch_loss=1.975287\n",
      "\tAccuracy for fine-tuning: 0.666000008583\n",
      "\tAccuracy for training from scratch: 0.288000001013\n",
      "iter 1450, finetune_loss=0.135009, scratch_loss=1.726422\n",
      "\tAccuracy for fine-tuning: 0.668000006676\n",
      "\tAccuracy for training from scratch: 0.27499999851\n",
      "iter 1455, finetune_loss=0.123760, scratch_loss=2.219388\n",
      "\tAccuracy for fine-tuning: 0.630000007153\n",
      "\tAccuracy for training from scratch: 0.295999999344\n",
      "iter 1460, finetune_loss=0.141711, scratch_loss=2.169718\n",
      "\tAccuracy for fine-tuning: 0.624000000954\n",
      "\tAccuracy for training from scratch: 0.155999998748\n",
      "iter 1465, finetune_loss=0.185947, scratch_loss=2.044202\n",
      "\tAccuracy for fine-tuning: 0.614999997616\n",
      "\tAccuracy for training from scratch: 0.292000001669\n",
      "iter 1470, finetune_loss=0.187452, scratch_loss=2.021773\n",
      "\tAccuracy for fine-tuning: 0.631999999285\n",
      "\tAccuracy for training from scratch: 0.23900000155\n",
      "iter 1475, finetune_loss=0.190339, scratch_loss=1.920034\n",
      "\tAccuracy for fine-tuning: 0.634000009298\n",
      "\tAccuracy for training from scratch: 0.264999999106\n",
      "iter 1480, finetune_loss=0.176662, scratch_loss=2.175143\n",
      "\tAccuracy for fine-tuning: 0.619999998808\n",
      "\tAccuracy for training from scratch: 0.238999997079\n",
      "iter 1485, finetune_loss=0.211239, scratch_loss=2.121962\n",
      "\tAccuracy for fine-tuning: 0.629999995232\n",
      "\tAccuracy for training from scratch: 0.317000001669\n",
      "iter 1490, finetune_loss=0.153192, scratch_loss=1.956017\n",
      "\tAccuracy for fine-tuning: 0.622999995947\n",
      "\tAccuracy for training from scratch: 0.312000000477\n",
      "iter 1495, finetune_loss=0.186348, scratch_loss=2.022871\n",
      "\tAccuracy for fine-tuning: 0.611000007391\n",
      "\tAccuracy for training from scratch: 0.28599999994\n",
      "iter 1500, finetune_loss=0.188345, scratch_loss=1.990056\n",
      "\tAccuracy for fine-tuning: 0.619999998808\n",
      "\tAccuracy for training from scratch: 0.269999995828\n",
      "iter 1505, finetune_loss=0.181262, scratch_loss=1.826025\n",
      "\tAccuracy for fine-tuning: 0.646000003815\n",
      "\tAccuracy for training from scratch: 0.302999998629\n",
      "iter 1510, finetune_loss=0.086389, scratch_loss=2.012637\n",
      "\tAccuracy for fine-tuning: 0.622999995947\n",
      "\tAccuracy for training from scratch: 0.256000000238\n",
      "iter 1515, finetune_loss=0.239811, scratch_loss=2.022973\n",
      "\tAccuracy for fine-tuning: 0.575999999046\n",
      "\tAccuracy for training from scratch: 0.295999997854\n",
      "iter 1520, finetune_loss=0.142518, scratch_loss=2.058674\n",
      "\tAccuracy for fine-tuning: 0.626000005007\n",
      "\tAccuracy for training from scratch: 0.334000003338\n",
      "iter 1525, finetune_loss=0.155290, scratch_loss=1.787975\n",
      "\tAccuracy for fine-tuning: 0.646999996901\n",
      "\tAccuracy for training from scratch: 0.279999999702\n",
      "iter 1530, finetune_loss=0.108288, scratch_loss=2.129741\n",
      "\tAccuracy for fine-tuning: 0.655000007153\n",
      "\tAccuracy for training from scratch: 0.296000000834\n",
      "iter 1535, finetune_loss=0.098808, scratch_loss=1.954178\n",
      "\tAccuracy for fine-tuning: 0.656000006199\n",
      "\tAccuracy for training from scratch: 0.303000000119\n",
      "iter 1540, finetune_loss=0.184051, scratch_loss=1.924922\n",
      "\tAccuracy for fine-tuning: 0.644999998808\n",
      "\tAccuracy for training from scratch: 0.294000002742\n",
      "iter 1545, finetune_loss=0.186508, scratch_loss=2.067055\n",
      "\tAccuracy for fine-tuning: 0.627999997139\n",
      "\tAccuracy for training from scratch: 0.309999999404\n",
      "iter 1550, finetune_loss=0.124911, scratch_loss=1.851523\n",
      "\tAccuracy for fine-tuning: 0.629000002146\n",
      "\tAccuracy for training from scratch: 0.275999999046\n",
      "iter 1555, finetune_loss=0.233667, scratch_loss=1.804986\n",
      "\tAccuracy for fine-tuning: 0.645999997854\n",
      "\tAccuracy for training from scratch: 0.283000001311\n",
      "iter 1560, finetune_loss=0.155815, scratch_loss=1.713976\n",
      "\tAccuracy for fine-tuning: 0.646999996901\n",
      "\tAccuracy for training from scratch: 0.356000003219\n",
      "iter 1565, finetune_loss=0.175833, scratch_loss=1.689096\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.240999998152\n",
      "iter 1570, finetune_loss=0.140204, scratch_loss=2.148584\n",
      "\tAccuracy for fine-tuning: 0.662000012398\n",
      "\tAccuracy for training from scratch: 0.33599999845\n",
      "iter 1575, finetune_loss=0.167803, scratch_loss=1.898979\n",
      "\tAccuracy for fine-tuning: 0.654000002146\n",
      "\tAccuracy for training from scratch: 0.346999999881\n",
      "iter 1580, finetune_loss=0.275891, scratch_loss=1.612530\n",
      "\tAccuracy for fine-tuning: 0.659000003338\n",
      "\tAccuracy for training from scratch: 0.321000000834\n",
      "iter 1585, finetune_loss=0.118875, scratch_loss=1.670163\n",
      "\tAccuracy for fine-tuning: 0.642000001669\n",
      "\tAccuracy for training from scratch: 0.329000005126\n",
      "iter 1590, finetune_loss=0.115561, scratch_loss=1.816988\n",
      "\tAccuracy for fine-tuning: 0.640000003576\n",
      "\tAccuracy for training from scratch: 0.28599999696\n",
      "iter 1595, finetune_loss=0.130393, scratch_loss=1.619103\n",
      "\tAccuracy for fine-tuning: 0.66400000453\n",
      "\tAccuracy for training from scratch: 0.28900000155\n",
      "iter 1600, finetune_loss=0.163039, scratch_loss=1.787698\n",
      "\tAccuracy for fine-tuning: 0.65000000596\n",
      "\tAccuracy for training from scratch: 0.354999998212\n",
      "iter 1605, finetune_loss=0.150103, scratch_loss=1.703133\n",
      "\tAccuracy for fine-tuning: 0.656000000238\n",
      "\tAccuracy for training from scratch: 0.33900000155\n",
      "iter 1610, finetune_loss=0.241042, scratch_loss=1.738459\n",
      "\tAccuracy for fine-tuning: 0.630000001192\n",
      "\tAccuracy for training from scratch: 0.318999999762\n",
      "iter 1615, finetune_loss=0.128968, scratch_loss=1.998528\n",
      "\tAccuracy for fine-tuning: 0.631000000238\n",
      "\tAccuracy for training from scratch: 0.270000003278\n",
      "iter 1620, finetune_loss=0.130175, scratch_loss=1.800637\n",
      "\tAccuracy for fine-tuning: 0.632000005245\n",
      "\tAccuracy for training from scratch: 0.269000004232\n",
      "iter 1625, finetune_loss=0.076102, scratch_loss=1.480166\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.310000002384\n",
      "iter 1630, finetune_loss=0.090902, scratch_loss=1.878243\n",
      "\tAccuracy for fine-tuning: 0.646000003815\n",
      "\tAccuracy for training from scratch: 0.330000001192\n",
      "iter 1635, finetune_loss=0.157629, scratch_loss=1.688460\n",
      "\tAccuracy for fine-tuning: 0.621000003815\n",
      "\tAccuracy for training from scratch: 0.337000009418\n",
      "iter 1640, finetune_loss=0.152252, scratch_loss=1.889886\n",
      "\tAccuracy for fine-tuning: 0.65000000596\n",
      "\tAccuracy for training from scratch: 0.348000001907\n",
      "iter 1645, finetune_loss=0.100903, scratch_loss=1.885195\n",
      "\tAccuracy for fine-tuning: 0.655999994278\n",
      "\tAccuracy for training from scratch: 0.341000002623\n",
      "iter 1650, finetune_loss=0.243184, scratch_loss=1.762054\n",
      "\tAccuracy for fine-tuning: 0.662000006437\n",
      "\tAccuracy for training from scratch: 0.234000000358\n",
      "iter 1655, finetune_loss=0.132054, scratch_loss=1.987325\n",
      "\tAccuracy for fine-tuning: 0.657000005245\n",
      "\tAccuracy for training from scratch: 0.324000000954\n",
      "iter 1660, finetune_loss=0.189272, scratch_loss=1.891606\n",
      "\tAccuracy for fine-tuning: 0.651000005007\n",
      "\tAccuracy for training from scratch: 0.287999998033\n",
      "iter 1665, finetune_loss=0.103018, scratch_loss=1.712459\n",
      "\tAccuracy for fine-tuning: 0.636000007391\n",
      "\tAccuracy for training from scratch: 0.309000000358\n",
      "iter 1670, finetune_loss=0.205817, scratch_loss=1.955897\n",
      "\tAccuracy for fine-tuning: 0.663000005484\n",
      "\tAccuracy for training from scratch: 0.329999996722\n",
      "iter 1675, finetune_loss=0.157574, scratch_loss=1.779130\n",
      "\tAccuracy for fine-tuning: 0.649000006914\n",
      "\tAccuracy for training from scratch: 0.36099999845\n",
      "iter 1680, finetune_loss=0.185207, scratch_loss=1.707180\n",
      "\tAccuracy for fine-tuning: 0.666000002623\n",
      "\tAccuracy for training from scratch: 0.318999999762\n",
      "iter 1685, finetune_loss=0.073011, scratch_loss=1.747502\n",
      "\tAccuracy for fine-tuning: 0.662999999523\n",
      "\tAccuracy for training from scratch: 0.34999999702\n",
      "iter 1690, finetune_loss=0.166075, scratch_loss=1.710884\n",
      "\tAccuracy for fine-tuning: 0.636000007391\n",
      "\tAccuracy for training from scratch: 0.33900000155\n",
      "iter 1695, finetune_loss=0.128091, scratch_loss=1.970573\n",
      "\tAccuracy for fine-tuning: 0.666000014544\n",
      "\tAccuracy for training from scratch: 0.379000002146\n",
      "iter 1700, finetune_loss=0.102974, scratch_loss=1.771941\n",
      "\tAccuracy for fine-tuning: 0.654000002146\n",
      "\tAccuracy for training from scratch: 0.368000000715\n",
      "iter 1705, finetune_loss=0.221691, scratch_loss=1.757168\n",
      "\tAccuracy for fine-tuning: 0.656999999285\n",
      "\tAccuracy for training from scratch: 0.301999999583\n",
      "iter 1710, finetune_loss=0.214636, scratch_loss=1.712945\n",
      "\tAccuracy for fine-tuning: 0.676000010967\n",
      "\tAccuracy for training from scratch: 0.32500000298\n",
      "iter 1715, finetune_loss=0.335296, scratch_loss=1.906557\n",
      "\tAccuracy for fine-tuning: 0.668000000715\n",
      "\tAccuracy for training from scratch: 0.287000000477\n",
      "iter 1720, finetune_loss=0.132760, scratch_loss=1.841884\n",
      "\tAccuracy for fine-tuning: 0.667999994755\n",
      "\tAccuracy for training from scratch: 0.378000003099\n",
      "iter 1725, finetune_loss=0.151590, scratch_loss=1.792155\n",
      "\tAccuracy for fine-tuning: 0.671000015736\n",
      "\tAccuracy for training from scratch: 0.391000002623\n",
      "iter 1730, finetune_loss=0.169462, scratch_loss=1.716812\n",
      "\tAccuracy for fine-tuning: 0.662999999523\n",
      "\tAccuracy for training from scratch: 0.352000007033\n",
      "iter 1735, finetune_loss=0.088002, scratch_loss=1.504876\n",
      "\tAccuracy for fine-tuning: 0.650999999046\n",
      "\tAccuracy for training from scratch: 0.341000005603\n",
      "iter 1740, finetune_loss=0.174694, scratch_loss=1.461747\n",
      "\tAccuracy for fine-tuning: 0.636000007391\n",
      "\tAccuracy for training from scratch: 0.351000005007\n",
      "iter 1745, finetune_loss=0.276316, scratch_loss=1.856390\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.361000004411\n",
      "iter 1750, finetune_loss=0.238036, scratch_loss=1.643432\n",
      "\tAccuracy for fine-tuning: 0.665999996662\n",
      "\tAccuracy for training from scratch: 0.373000001907\n",
      "iter 1755, finetune_loss=0.142889, scratch_loss=1.609431\n",
      "\tAccuracy for fine-tuning: 0.668000006676\n",
      "\tAccuracy for training from scratch: 0.398000001907\n",
      "iter 1760, finetune_loss=0.151464, scratch_loss=1.759659\n",
      "\tAccuracy for fine-tuning: 0.649000012875\n",
      "\tAccuracy for training from scratch: 0.373999997973\n",
      "iter 1765, finetune_loss=0.152621, scratch_loss=1.553694\n",
      "\tAccuracy for fine-tuning: 0.640000009537\n",
      "\tAccuracy for training from scratch: 0.36099999547\n",
      "iter 1770, finetune_loss=0.115303, scratch_loss=1.443527\n",
      "\tAccuracy for fine-tuning: 0.655999988317\n",
      "\tAccuracy for training from scratch: 0.351000007987\n",
      "iter 1775, finetune_loss=0.176773, scratch_loss=1.692161\n",
      "\tAccuracy for fine-tuning: 0.656999999285\n",
      "\tAccuracy for training from scratch: 0.334000003338\n",
      "iter 1780, finetune_loss=0.157038, scratch_loss=1.613372\n",
      "\tAccuracy for fine-tuning: 0.663999998569\n",
      "\tAccuracy for training from scratch: 0.43599999845\n",
      "iter 1785, finetune_loss=0.271554, scratch_loss=1.547812\n",
      "\tAccuracy for fine-tuning: 0.669999998808\n",
      "\tAccuracy for training from scratch: 0.403999999166\n",
      "iter 1790, finetune_loss=0.269666, scratch_loss=1.837024\n",
      "\tAccuracy for fine-tuning: 0.656999999285\n",
      "\tAccuracy for training from scratch: 0.384000000358\n",
      "iter 1795, finetune_loss=0.133743, scratch_loss=1.596409\n",
      "\tAccuracy for fine-tuning: 0.660000002384\n",
      "\tAccuracy for training from scratch: 0.357000005245\n",
      "iter 1800, finetune_loss=0.155303, scratch_loss=1.277047\n",
      "\tAccuracy for fine-tuning: 0.654999995232\n",
      "\tAccuracy for training from scratch: 0.355000004172\n",
      "iter 1805, finetune_loss=0.130845, scratch_loss=1.663776\n",
      "\tAccuracy for fine-tuning: 0.661000001431\n",
      "\tAccuracy for training from scratch: 0.351000002027\n",
      "iter 1810, finetune_loss=0.133540, scratch_loss=1.541785\n",
      "\tAccuracy for fine-tuning: 0.663999992609\n",
      "\tAccuracy for training from scratch: 0.41099999547\n",
      "iter 1815, finetune_loss=0.143630, scratch_loss=1.447352\n",
      "\tAccuracy for fine-tuning: 0.650999993086\n",
      "\tAccuracy for training from scratch: 0.38900000155\n",
      "iter 1820, finetune_loss=0.068140, scratch_loss=1.754274\n",
      "\tAccuracy for fine-tuning: 0.647999989986\n",
      "\tAccuracy for training from scratch: 0.39699999392\n",
      "iter 1825, finetune_loss=0.113073, scratch_loss=1.538174\n",
      "\tAccuracy for fine-tuning: 0.642000007629\n",
      "\tAccuracy for training from scratch: 0.323000004888\n",
      "iter 1830, finetune_loss=0.168768, scratch_loss=1.667568\n",
      "\tAccuracy for fine-tuning: 0.657000005245\n",
      "\tAccuracy for training from scratch: 0.393999999762\n",
      "iter 1835, finetune_loss=0.239300, scratch_loss=1.756073\n",
      "\tAccuracy for fine-tuning: 0.646000009775\n",
      "\tAccuracy for training from scratch: 0.384999996424\n",
      "iter 1840, finetune_loss=0.276155, scratch_loss=1.538831\n",
      "\tAccuracy for fine-tuning: 0.65\n",
      "\tAccuracy for training from scratch: 0.419999998808\n",
      "iter 1845, finetune_loss=0.148760, scratch_loss=1.679620\n",
      "\tAccuracy for fine-tuning: 0.634000009298\n",
      "\tAccuracy for training from scratch: 0.398999997973\n",
      "iter 1850, finetune_loss=0.195993, scratch_loss=1.669753\n",
      "\tAccuracy for fine-tuning: 0.618999999762\n",
      "\tAccuracy for training from scratch: 0.383999997377\n",
      "iter 1855, finetune_loss=0.216053, scratch_loss=1.526765\n",
      "\tAccuracy for fine-tuning: 0.648000001907\n",
      "\tAccuracy for training from scratch: 0.401999995112\n",
      "iter 1860, finetune_loss=0.099074, scratch_loss=1.785642\n",
      "\tAccuracy for fine-tuning: 0.659000003338\n",
      "\tAccuracy for training from scratch: 0.399000003934\n",
      "iter 1865, finetune_loss=0.210136, scratch_loss=1.553127\n",
      "\tAccuracy for fine-tuning: 0.626000005007\n",
      "\tAccuracy for training from scratch: 0.398999994993\n",
      "iter 1870, finetune_loss=0.161908, scratch_loss=1.538778\n",
      "\tAccuracy for fine-tuning: 0.66099999547\n",
      "\tAccuracy for training from scratch: 0.406999999285\n",
      "iter 1875, finetune_loss=0.088104, scratch_loss=1.443362\n",
      "\tAccuracy for fine-tuning: 0.655000007153\n",
      "\tAccuracy for training from scratch: 0.376000002027\n",
      "iter 1880, finetune_loss=0.187553, scratch_loss=1.706278\n",
      "\tAccuracy for fine-tuning: 0.612999993563\n",
      "\tAccuracy for training from scratch: 0.40000000298\n",
      "iter 1885, finetune_loss=0.108697, scratch_loss=1.438066\n",
      "\tAccuracy for fine-tuning: 0.639999997616\n",
      "\tAccuracy for training from scratch: 0.407999995351\n",
      "iter 1890, finetune_loss=0.190076, scratch_loss=1.552284\n",
      "\tAccuracy for fine-tuning: 0.632000005245\n",
      "\tAccuracy for training from scratch: 0.373000001907\n",
      "iter 1895, finetune_loss=0.183102, scratch_loss=1.563442\n",
      "\tAccuracy for fine-tuning: 0.616000002623\n",
      "\tAccuracy for training from scratch: 0.417999991775\n",
      "iter 1900, finetune_loss=0.068593, scratch_loss=1.395640\n",
      "\tAccuracy for fine-tuning: 0.597999995947\n",
      "\tAccuracy for training from scratch: 0.433999994397\n",
      "iter 1905, finetune_loss=0.138110, scratch_loss=1.456115\n",
      "\tAccuracy for fine-tuning: 0.654000002146\n",
      "\tAccuracy for training from scratch: 0.414999994636\n",
      "iter 1910, finetune_loss=0.091951, scratch_loss=1.403471\n",
      "\tAccuracy for fine-tuning: 0.656999993324\n",
      "\tAccuracy for training from scratch: 0.384999996424\n",
      "iter 1915, finetune_loss=0.136619, scratch_loss=1.396562\n",
      "\tAccuracy for fine-tuning: 0.647999995947\n",
      "\tAccuracy for training from scratch: 0.398999997973\n",
      "iter 1920, finetune_loss=0.180389, scratch_loss=1.572356\n",
      "\tAccuracy for fine-tuning: 0.656999999285\n",
      "\tAccuracy for training from scratch: 0.392999997735\n",
      "iter 1925, finetune_loss=0.116137, scratch_loss=1.726035\n",
      "\tAccuracy for fine-tuning: 0.669999998808\n",
      "\tAccuracy for training from scratch: 0.439999994636\n",
      "iter 1930, finetune_loss=0.170460, scratch_loss=1.393452\n",
      "\tAccuracy for fine-tuning: 0.663000011444\n",
      "\tAccuracy for training from scratch: 0.430999997258\n",
      "iter 1935, finetune_loss=0.151703, scratch_loss=1.495350\n",
      "\tAccuracy for fine-tuning: 0.658000004292\n",
      "\tAccuracy for training from scratch: 0.416999998689\n",
      "iter 1940, finetune_loss=0.136261, scratch_loss=1.402052\n",
      "\tAccuracy for fine-tuning: 0.651999998093\n",
      "\tAccuracy for training from scratch: 0.404999998212\n",
      "iter 1945, finetune_loss=0.072513, scratch_loss=1.317074\n",
      "\tAccuracy for fine-tuning: 0.66400001049\n",
      "\tAccuracy for training from scratch: 0.387000000477\n",
      "iter 1950, finetune_loss=0.155259, scratch_loss=1.710468\n",
      "\tAccuracy for fine-tuning: 0.674000000954\n",
      "\tAccuracy for training from scratch: 0.413999995589\n",
      "iter 1955, finetune_loss=0.184454, scratch_loss=1.447056\n",
      "\tAccuracy for fine-tuning: 0.66099999547\n",
      "\tAccuracy for training from scratch: 0.37499999404\n",
      "iter 1960, finetune_loss=0.177731, scratch_loss=1.302045\n",
      "\tAccuracy for fine-tuning: 0.649000006914\n",
      "\tAccuracy for training from scratch: 0.390999999642\n",
      "iter 1965, finetune_loss=0.160930, scratch_loss=1.479612\n",
      "\tAccuracy for fine-tuning: 0.637999999523\n",
      "\tAccuracy for training from scratch: 0.404999998212\n",
      "iter 1970, finetune_loss=0.094859, scratch_loss=1.382423\n",
      "\tAccuracy for fine-tuning: 0.653000003099\n",
      "\tAccuracy for training from scratch: 0.38599999845\n",
      "iter 1975, finetune_loss=0.214808, scratch_loss=1.219542\n",
      "\tAccuracy for fine-tuning: 0.656999999285\n",
      "\tAccuracy for training from scratch: 0.423999997973\n",
      "iter 1980, finetune_loss=0.202718, scratch_loss=1.522544\n",
      "\tAccuracy for fine-tuning: 0.649000000954\n",
      "\tAccuracy for training from scratch: 0.428000003099\n",
      "iter 1985, finetune_loss=0.095391, scratch_loss=1.306338\n",
      "\tAccuracy for fine-tuning: 0.644000011683\n",
      "\tAccuracy for training from scratch: 0.434999996424\n",
      "iter 1990, finetune_loss=0.160153, scratch_loss=1.290131\n",
      "\tAccuracy for fine-tuning: 0.633000004292\n",
      "\tAccuracy for training from scratch: 0.427000001073\n",
      "iter 1995, finetune_loss=0.134751, scratch_loss=1.461121\n",
      "\tAccuracy for fine-tuning: 0.661000001431\n",
      "\tAccuracy for training from scratch: 0.478999996185\n",
      "Finish with total time: 7462.84 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#solver = caffe.SGDSolver('/u/zexuan/caffe/caffe/models/finetune_flickr_style/solver.prototxt')\n",
    "solver = caffe.SGDSolver('/u/zexuan/caffe/caffe/models/finetune_stroke_cls/solver.prototxt')\n",
    "solver.net.copy_from('/u/zexuan/caffe/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')\n",
    "# For reference, we also create a solver that does no finetuning.\n",
    "#scratch_solver = caffe.SGDSolver('/u/zexuan/caffe/caffe/models/finetune_flickr_style/solver.prototxt')\n",
    "scratch_solver = caffe.SGDSolver('/u/zexuan/caffe/caffe/models/finetune_stroke_cls/solver.prototxt')\n",
    "\n",
    "# We run the solver for niter times, and record the training loss.\n",
    "\n",
    "for it in range(niter):\n",
    "    solver.step(1)  # SGD by Caffe\n",
    "    scratch_solver.step(1)\n",
    "    # store the train loss\n",
    "    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    scratch_train_loss[it] = scratch_solver.net.blobs['loss'].data\n",
    "    if it % 5 == 0:\n",
    "        print 'iter %d, finetune_loss=%f, scratch_loss=%f' % (it, train_loss[it], scratch_train_loss[it])\n",
    "        \n",
    "        test_iters = 10\n",
    "        accuracy = 0\n",
    "        scratch_accuracy = 0\n",
    "        for it in np.arange(test_iters):\n",
    "            solver.test_nets[0].forward()\n",
    "            #solver.net.forward()\n",
    "            accuracy += solver.test_nets[0].blobs['accuracy'].data\n",
    "            scratch_solver.test_nets[0].forward()\n",
    "            #scratch_solver.net.forward()\n",
    "            scratch_accuracy += scratch_solver.test_nets[0].blobs['accuracy'].data\n",
    "        accuracy /= test_iters\n",
    "        scratch_accuracy /= test_iters\n",
    "        print '\\tAccuracy for fine-tuning:', accuracy\n",
    "        print '\\tAccuracy for training from scratch:', scratch_accuracy\n",
    "\n",
    "print 'Finish with total time: %g seconds'%(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f645fffc390>,\n",
       " <matplotlib.lines.Line2D at 0x7f645fffc610>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/82NM3YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63ed6db450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.plot(np.vstack([train_loss, scratch_train_loss]).clip(0, 4).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fine-tuning: 0.637999999523\n",
      "Accuracy for training from scratch: 0.431000000238\n"
     ]
    }
   ],
   "source": [
    "test_iters = 10\n",
    "accuracy = 0\n",
    "scratch_accuracy = 0\n",
    "for it in np.arange(test_iters):\n",
    "    solver.test_nets[0].forward()\n",
    "    #solver.net.forward()\n",
    "    accuracy += solver.test_nets[0].blobs['accuracy'].data\n",
    "    scratch_solver.test_nets[0].forward()\n",
    "    #scratch_solver.net.forward()\n",
    "    scratch_accuracy += scratch_solver.test_nets[0].blobs['accuracy'].data\n",
    "accuracy /= test_iters\n",
    "scratch_accuracy /= test_iters\n",
    "print 'Accuracy for fine-tuning:', accuracy\n",
    "print 'Accuracy for training from scratch:', scratch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dir(solver.test_nets[1])\n",
    "solver.net.save('fine_tune_stroke_cls_2000iter.caffemodel')\n",
    "solver.test_nets[0].save('fine_tune_stroke_cls_testnet_2000iter.caffemodel')\n",
    "scratch_solver.net.save('fine_tune_stroke_cls_scratch_2000iter.caffemodel')\n",
    "scratch_solver.test_nets[0].save('fine_tune_stroke_cls_testnet_scratch_2000iter.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
